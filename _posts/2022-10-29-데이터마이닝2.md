---
layout: post  
title: "[데이터마이닝] 2장. 데이터 전처리와 모형평가"
date: 2022-10-29
excerpt: "R 데이터마이닝의 2장 내용을 정리하였습니다."
tag:
- 데이터마이닝
comments: true
--- 

# 2.1 데이터 전처리

---

- R의 {caret} 패키지 이용 : 예측변수를 전처리하는 함수 제공. 이 패키지는 모든 데이터를 수치형으로 가정. (즉, 요인은 model.matrix{stats}, dummyVars{caret} 함수 또는 다른 방법을 통해 더미 변수로 변환되었다고 가정)

## 2.1.1 영-과 영근처-분산 예측변수의 처리
- 한 개의 값만을 취하는(영-분산) 예측변수를 생성할 수 있음
- 영-분산 예측변수는 모형을 망가뜨리거나 불안정 적합의 원인이 됨
- 예측변수는 매우 낮은 빈도로 발생하는 몇 개의 값만을 취할 수도 있음

### 예제 1) mdrr{caret} 자료에서 불균형적인 몇 개의 수치만을 취하는 **nR11** 변수
```
> data(mdrr)
> data.frame(table(mdrrDescr$nR11)) 
  Var1 Freq
1    0  501
2    1    4
3    2   23
```
- 주의할 점 : 예측변수들이 교차타당성/부트스트랩 하위 샘플로 분할될 때 영-분산 예측변수가 되거나, 일부 샘플이 과도한 영향을 미치게 되는 경우
- 값 0의 빈도가 너무 큼...
- 영-/영근처-분산 예측변수는 모형화 이전에 제거되어야 함

#### ✅ 빈도비율(frequency ratio)
$$\frac{일순위빈발값의 빈도}{차순위 빈발값의 빈도} = \frac{501}{23} = 21.78261$$
- 정상적인 예측변수에서는 1에 가까운 값
- 불균형적인 데이터에 대해서는 매우 큰 값
- 지정된 임계값보다 크면 영-분산에 가까움

#### ✅ 유일 값들의 비율(percent of unique values)
$$\frac{유일 값들의 수(종류)}{전체 표본의 수}×100$$
$$\frac{3}{528}×100 = 0.5681818$$
- 데이터의 집중도가 커질수록 0에 가까워짐
- 지정된 임곗값보다 작으면 영-분산에 가까움

#### ⭐ 빈도비율과 유일값들의 비율을 모두 사용하면 세분성이 낮으나(집중도가 높으나), 이산 균일분포와 같이 고르게 분포된 데이터를 잘못 판단하지는 않을 것이다!

#### ✔️ 영근처-분산의 변수를 식별, 문제가 되는 변수의 위치를 반환 : nearZeroVar() 함수
- saveMetrics=TRUE : 각 예측값에 대한 빈도비율(freqRatio)과 유일값들의 비율(percentUnique)을 얻을 수 있고 각 변수가 영-분산(zeroVar) 또는 영-근처 분산(nzv)을 가지는 알려줌.
- 디폴트 임계값 : 유일값 비율 - 10% 이하, 빈도비율 19(95/5)보다 큰 경우 영-근처 분산으로 분류됨
- 임계값 설정 : 유일값 비율 - UniqueCut=, 빈도비율 - freqCut=
```
> nzv <- nearZeroVar(mdrrDescr, saveMetrics = TRUE) # check option saveMetrics=T ; detail information
> str(nzv)
'data.frame':	342 obs. of  4 variables:
 $ freqRatio    : num  1.25 1.12 1 1.25 1.25 ...
 $ percentUnique: num  90 42.6 83 84.3 82.8 ...
 $ zeroVar      : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...
 $ nzv          : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...
> nzv[nzv$nzv, ][1:10,] # 영근처분산인 변수들
       freqRatio percentUnique zeroVar  nzv
nTB     23.00000     0.3787879   FALSE TRUE
nBR    131.00000     0.3787879   FALSE TRUE
nI     527.00000     0.3787879   FALSE TRUE
nR03   527.00000     0.3787879   FALSE TRUE
nR08   527.00000     0.3787879   FALSE TRUE
nR11    21.78261     0.5681818   FALSE TRUE
nR12    57.66667     0.3787879   FALSE TRUE
D.Dr03 527.00000     0.3787879   FALSE TRUE
D.Dr07 123.50000     5.8712121   FALSE TRUE
D.Dr08 527.00000     0.3787879   FALSE TRUE
> dim(mdrrDescr) # # of obs. & var
[1] 528 342
> nzv <- nearZeroVar(mdrrDescr) ;nzv # save near-zero-variables
 [1]  22  31  32  34  38  41  42 259 262 263 264 266 267 270 271 272 273 274
[19] 276 277 278 279 280 281 282 283 284 285 286 287 288 327 328 330 331 333
[37] 334 335 336 337 338 339 340 341 342
> filteredDescr <- mdrrDescr[, -nzv] # delete near-zero-variables(영근처 분산 제거)
> dim(filteredDescr)
[1] 528 297 # 297개 변수(영근처-분산 제거 후, 342-297=45개 삭제)
```

## 2.1.2 상관된 예측변수의 식별 : 중복변수 제거
- 상관관계가 있는 예측변수에 대해서도 잘 작동하는 일부 모형이 있지만(PLS회귀), 다른 모형들은 예측변수들 간 상관관계를 줄어야 함(ex. 다중공선성 영향)

### 예제 2) 주어진 상관 행렬에 대해 findCorrelation() 함수는 다음 절차를 통해 제거해야 할 예측변수를 제공
```
> descrCor <- cor(filteredDescr) # correlation
> (highCorr <- sum(abs(descrCor[upper.tri(descrCor)]) > .999)) # sum() 함수 : 논리형 자료의 합
[1] 65 # 상관계수가 0.999 이상인 경우가 65개(297_C_2 = 43956개 중)
> summary(descrCor[upper.tri(descrCor)])
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-0.99607 -0.05373  0.25006  0.26078  0.65527  1.00000 
```

#### ✔️ mdrr 자료에서 0.75 이상의 절대 상관계수를 갖는 에측변수를 제거하는 과정과 그 효과
```
> highlyCorDescr <- findCorrelation(descrCor, cutoff = 0.75) # 0.75 이상
> filteredDescr <- filteredDescr[, -highlyCorDescr] # 제거
> descrCor2 <- cor(filteredDescr) 
> summary(descrCor2[upper.tri(descrCor2)]) # 제거한 결과 모두 0.75 이하
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-0.70728 -0.05378  0.04418  0.06692  0.18858  0.74458 
```

## 2.1.3 예측변수의 변환

## (a) 중심화와 척도화

### ✅ 중심화
$$x_i - \bar{x}$$

### ✅ 척도화
$$\frac{x_i}{s}$$

### ✅ 표준화(중심화와 척도화 동시 수행)
$$\frac{x_i-\bar{x}}{s}, 평균=0, 분산=1$$

### cf) zero-one 표준편차
$$y_i = \frac{x_i-x_1}{x_n-x_1}, 0<=y_i<=1 $$

### ✅ preProcess() 함수 : 중심화(centring)와 척도화(scaling)를 포함하여 예측변수에 대해 많은 연산 제공
- 각 연산에 필요한 모수를 추정
- predict.preProcess() : 특정 데이터셋에 적용, train() 함수를 호출할 때의 인터페이스
- 특정 데이터 셋으로부터 요구하는 것(훈련 데이터)을 추정한 다음, 이 값을 재계산하지 않고 임의의 데이터 셋에 이들 변환 제공
- method = "ranges" 옵션은 0과 1 사이의 값으로 데이터 변환해줌

### 예제 3) preProcess() 함수는 실제로 데이터를 전처리하지 않으며 predict.preProcess() 함수는 이 데이터셋(훈련용)과 다른 데이터셋(검증용)을 전처리하는데 사용
- train(모형구축), validation(구축된 모형 검증 및 개선), test(모형 성능 평가)
```
> set.seed(200)
> train, test 데이터
> inTrain <- sample(seq(along = mdrrClass), length(mdrrClass)/2)
> training <- filteredDescr[inTrain, ]
> test <- filteredDescr[-inTrain, ]
> # 정답 데이터
> trainMDRR <- mdrrClass[inTrain]
> testMDRR <- mdrrClass[-inTrain]
> 
> # 중심화와 척도화 수행
> preProcValues <- preProcess(training, method = c("center", "scale"))
> trainTransformed <- predict(preProcValues, training)
> testTransformed <- predict(preProcValues, test)
```

## (b) 박스-콕스 변환
- 목적 : 데이터를 정규분포에 가깝게 만들거나 데이터의 분산을 안정화
- preProcess() 함수에서 method="BoxCox" 옵션 : 예측변수에 대한 박스-콕스 변환의 차수 수정(데이터가 영보다 큰 경우)
- NA 값은 변환될 수 없는 예측인자. 이 변환은 데이터가 0보다 커야 함.
- 유사 변형으로 Yeo-Johnson, Manly의 지수변환
- R의 박스콕스 변환 수행 함수 : boxcox{MASS}, bcPower{car}, powerTransform{car}

### 예제 4) 예측변수에 대해 박스콕스 변환 수행
```
> # box-cox trans
> preProcValues2 <- preProcess(training, method = "BoxCox")
> trainBC <- predict(preProcValues2, training)
> testBC <- predict(preProcValues2, test)
> preProcValues2
Created from 264 samples and 31 variables

Pre-processing:
  - Box-Cox transformation (31)
  - ignored (0)

Lambda estimates for Box-Cox transformation:
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
-2.0000 -0.2500  0.4000  0.4548  1.4500  2.0000 
```

## 2.1.4 기타 전처리 방법

## (a) 더미변수 생성
- {caret}의 dummyVars() : 하나 이상의 요인(factor)으로부터 완전한 더미변수 집합 생성. 모형식과 데이터셋을 활용하여 생성된 객체에 predict() 함수 적용하여 더미변수 만듦

### 예제 5) etitanic{earth} 자료는 두 개의 요인 pclass, sex를 포함. 이 자료에 대해 더미변수를 생성하라.
```
> library(earth)
> data(etitanic)
> str(etitanic)
'data.frame':	1046 obs. of  6 variables:
 $ pclass  : Factor w/ 3 levels "1st","2nd","3rd": 1 1 1 1 1 1 1 1 1 1 ...
 $ survived: int  1 1 0 0 0 1 1 0 1 0 ...
 $ sex     : Factor w/ 2 levels "female","male": 1 2 1 2 1 2 1 2 1 2 ...
 $ age     : num  29 0.917 2 30 25 ...
 $ sibsp   : int  0 1 1 1 1 0 1 0 2 0 ...
 $ parch   : int  0 2 2 2 2 0 0 0 0 0 ...
> # model.matrix{stats} : # of (categories-1)
> head(model.matrix(survived ~ ., data = etitanic))
  (Intercept) pclass2nd pclass3rd sexmale     age sibsp parch
1           1         0         0       0 29.0000     0     0
2           1         0         0       1  0.9167     1     2
3           1         0         0       0  2.0000     1     2
4           1         0         0       1 30.0000     1     2
5           1         0         0       0 25.0000     1     2
6           1         0         0       1 48.0000     0     0
> # dummyVar{caret} : # of (categories)
> dummy.1 <- dummyVars(survived ~ ., data = etitanic)
> head(predict(dummy.1, newdata = etitanic))
  pclass.1st pclass.2nd pclass.3rd sex.female sex.male     age sibsp parch
1          1          0          0          1        0 29.0000     0     0
2          1          0          0          0        1  0.9167     1     2
3          1          0          0          1        0  2.0000     1     2
4          1          0          0          0        1 30.0000     1     2
5          1          0          0          1        0 25.0000     1     2
6          1          0          0          0        1 48.0000     0     0
```
- 위 결과는 절편이 없으며 각 요인은 각 수준에 대해 더미변수를 가지므로, 이런 더미변수는 lm()을 비롯한 일부 모형함수에 유용하지 않을 수 있음에 유의

## (b) 선형종속성
- {caret}의 findLinearCombos() : 행렬의 QR분해를 사용하여 선형결합의 집합을 열거(존재하는 경우에)

### 예제 6) 열이 0 또는 1의 값으로 채워진 자료에 대해 선형종속성을 가진 열 찾기
```
> ltfrDesign <- matrix(0, nrow = 6, ncol = 6)
> ltfrDesign[, 1] <- c(1, 1, 1, 1, 1, 1)
> ltfrDesign[, 2] <- c(1, 1, 1, 0, 0, 0)
> ltfrDesign[, 3] <- c(0, 0, 0, 1, 1, 1)
> ltfrDesign[, 4] <- c(1, 0, 0, 1, 0, 0)
> ltfrDesign[, 5] <- c(0, 1, 0, 0, 1, 0)
> ltfrDesign[, 6] <- c(0, 0, 1, 0, 0, 1)
> 
> comboInfo <- findLinearCombos(ltfrDesign)
> comboInfo
$linearCombos
$linearCombos[[1]]
[1] 3 1 2

$linearCombos[[2]]
[1] 6 1 4 5


$remove
[1] 3 6

> ltfrDesign[, -comboInfo$remove]
     [,1] [,2] [,3] [,4]
[1,]    1    1    1    0
[2,]    1    1    0    1
[3,]    1    1    0    0
[4,]    1    0    1    0
[5,]    1    0    0    1
[6,]    1    0    0    0
```
- 맨 처음 생성해준 행렬은 선형독립성 성립하지 않음 : 2와 3열의 합은 1과 같고, 4/5/6 열의 합은 1열과 같아짐
- findLinearCombos()함수는 종속성을 열거하고 선형종속성을 없애기 위해 제거할 열 위치의 벡터를 제공

## (c) 결측값 대치
- preProcess() 함수 : 훈련용 자료에서의 정보만을 기반으로 데이터 셋의 결측값을 대치(impute)
- 방법 1. k-근접 이웃 : 임의의 하나의 표본에 대해 k개의 가장 가까운 이웃을 훈련용 자료에서 발견하여 이들 값을 이용하여(예. 평균) 예측변수의 결측값 대치. -> 'method=' 인자가 무엇이든 관계없이 자동적으로 데이터의 중심화와 척도화 수행
- 방법 2. 배깅 트리 모형 : 데이터의 각 예측변수에 대해 훈련용 자료의 다른 모든 예측변수를 사용하여 배깅 트리가 생성됨. 새로운 표본이 결측 예측값을 가질 때, 이 값을 예측하는 데 배깅 모형 사용. -> 근접 이웃 기법보다 강력하지만 계산 비용이 높음.

### 예제 7) airquality 자료의 결측값을 k-인접이웃 방법으로 대치. preProcess()가 값을 돌려주진 않고 대치된 값을 확인하고자 할 때는 predict() 함수 사용.
```
> library(caret)
> data(airquality); summary(airquality) # summary() 결측값 개수 확인
     Ozone           Solar.R           Wind             Temp      
 Min.   :  1.00   Min.   :  7.0   Min.   : 1.700   Min.   :56.00  
 1st Qu.: 18.00   1st Qu.:115.8   1st Qu.: 7.400   1st Qu.:72.00  
 Median : 31.50   Median :205.0   Median : 9.700   Median :79.00  
 Mean   : 42.13   Mean   :185.9   Mean   : 9.958   Mean   :77.88  
 3rd Qu.: 63.25   3rd Qu.:258.8   3rd Qu.:11.500   3rd Qu.:85.00  
 Max.   :168.00   Max.   :334.0   Max.   :20.700   Max.   :97.00  
 NA's   :37       NA's   :7                                       
     Month            Day      
 Min.   :5.000   Min.   : 1.0  
 1st Qu.:6.000   1st Qu.: 8.0  
 Median :7.000   Median :16.0  
 Mean   :6.993   Mean   :15.8  
 3rd Qu.:8.000   3rd Qu.:23.0  
 Max.   :9.000   Max.   :31.0  
                               
> imp.1 <- preProcess(airquality, method=c("knnImpute")) # option method "knnImpute"
> library(RANN)
> imp.2 <- predict(imp.1, airquality); summary(imp.2)
     Ozone             Solar.R              Wind              Temp        
 Min.   :-1.24680   Min.   :-1.98684   Min.   :-2.3439   Min.   :-2.3119  
 1st Qu.:-0.67083   1st Qu.:-0.75430   1st Qu.:-0.7259   1st Qu.:-0.6215  
 Median :-0.24643   Median : 0.13401   Median :-0.0731   Median : 0.1181  
 Mean   : 0.00666   Mean   :-0.00895   Mean   : 0.0000   Mean   : 0.0000  
 3rd Qu.: 0.63268   3rd Qu.: 0.77803   3rd Qu.: 0.4378   3rd Qu.: 0.7520  
 Max.   : 3.81566   Max.   : 1.64414   Max.   : 3.0492   Max.   : 2.0198  
     Month                Day          
 Min.   :-1.407294   Min.   :-1.67002  
 1st Qu.:-0.701340   1st Qu.:-0.88035  
 Median : 0.004614   Median : 0.02212  
 Mean   : 0.000000   Mean   : 0.00000  
 3rd Qu.: 0.710568   3rd Qu.: 0.81178  
 Max.   : 1.416522   Max.   : 1.71426  
```
- preProcess{caret}은 요인 객체에 대한 결측값 대치를 아직 지원 안하지만 다양한 분석을 지원하는 {caret} 패키지와 결합되어 데이터마이닝 분석에서 편리.

## (d) 군집거리 계산
- {caret} 패키지에는 군집중심까지의 거리를 기반으로 새로운 예측변수를 생성하는 함수가 포함되어 있음(선형판별분석 방법과 유사). 요인변수의 각 수준에 대해 군집 중심과 공분산행렬이 계산됨. 새로운 표본에 대해, 각 군집중심까지의 마할라노비스 거리가 계산되고 이 값은 추가 예측변수로 사용 가능(결정 경계의 참값이 실제 선형일 때 비선형모형에 대해 유용할 수 있음).
- 표본보다 군집 내에 예측변수가 많은 경우, classDist() 함수는 pca=, keep= 옵션을 통해 각 군집 내에서 주성분분석이 가능하도록 하여, 특이(singular) 공분산행렬 문제를 해결. 
- predict.classDict() : 군집거리 생성, 디폴트로 거리가 기록되지만 trans= 옵션으로 변경 가능.

### 예제 8) iris 자료에 대해 군집거리 계산 수행. 훈련용 자료에서 개선된 결과(중심과 공분산행렬)를 검증용 자료에 적용하여 거리 계산.
```
> # 훈련용 자료로부터 군집 중심과 공분산 행렬 계산
> trainSet <- sample(1:150, 100)
> distData <- classDist(iris[trainSet, 1:4], iris$Species[trainSet])
> distData$values
$setosa
$setosa$means # setosa 그룹에 속하는 자료들의 평균
Sepal.Length  Sepal.Width Petal.Length  Petal.Width 
   4.9805556    3.3944444    1.4500000    0.2305556 

$setosa$A # setosa 그룹에 속하는 자료들의 공분산행렬
             Sepal.Length Sepal.Width Petal.Length Petal.Width
Sepal.Length    18.724979  -11.465468    -7.995022  -11.066347
Sepal.Width    -11.465468   14.701227     1.791880   -1.307182
Petal.Length    -7.995022    1.791880    41.576107   -8.212566
Petal.Width    -11.066347   -1.307182    -8.212566  183.906457

...(생략)

> 
> # 검증용 자료에 대해 군집중심까지의 마할라노비스 거리 계산
> newDist <- predict(distData, iris[-trainSet, 1:4])
> newDist[1:10,]
   dist.setosa dist.versicolor dist.virginica
5  -0.22887110        4.675346       5.481087
6   1.84867412        4.677837       5.481987
10  1.35489216        4.431416       5.294163
15  2.53101360        5.039235       5.810046
17  2.04893921        4.791270       5.624133
18  0.06159816        4.540502       5.434719
24  2.65975867        4.143838       5.179908
26  1.21659561        4.242823       5.206297
33  2.17944618        5.057810       5.679893
39  1.02053687        4.263521       5.208212
> 
> # 검증용 자료에 대한 군집거리의 산점도 행렬
> splom(newDist, groups = iris$Species[-trainSet], auto.key=list(columns=3))
```
![](https://user-images.githubusercontent.com/77424107/198834216-d59b7c7a-7ab6-4aa1-94d5-8bdb5755a7f0.png)

# 2.2 모형 평가

## 2.2.1 최적의 부분 회귀모형(best subset regression)의 선택 기준
- 예측변수들의 모든 가능한 부분집합을 예측변수로 하는 회귀모형(all possible subset regression)을 적합하고, 이 가운데 아래 기준에 가장 잘 부합하는 모형을 찾는 방법

![](https://user-images.githubusercontent.com/77424107/198834630-2800f9ef-f8b3-4cb1-bb3b-415c08885aaf.png)
![](https://user-images.githubusercontent.com/77424107/198834694-76849303-3134-4d20-883b-1cba605aedde.png)

### ✅ 기준에 따른 변수선택 절차
- 1️⃣ 결정계수는 p에 대해 증가함수이다. 모형의 단순성을 위해 증가가 둔화되는 p를 선택.
- 2️⃣ 수정결정계수는 결정계수의 단점을 보완하여 설명력이 약한 예측변수를 추가할 때는 오히려 감소. 따라서 가장 큰 값을 가지는 p 선택.
- 3️⃣ 평균제곱오차가 최소가 되는 p 선택. 수정결정계수의 결과와 동일.
- 4️⃣ C_p의 값이 p와 가장 가까운 값을 가지는 p를 선택

## 2.2.2 정보기준과 PRESS

## (a) 정보기준
- **회귀모형의 비교**를 위함
- C_p 통계량보다 더 현실적인 방법 : C_p가 실제보다 모형 간 더 큰 차이가 있는 것처럼 보이게 하는 경향이 있음
- 세 종류 모두 **작은 값 가질수록 우수**
- BIC는 AIC에 비해 모수의 수에 더 큰 벌점을 부여하므로, 좀 더 단순한 모형을 선호 -> AIC 기준이 과대적합의 경향이 있다는 비판에 대한 보완

![](https://user-images.githubusercontent.com/77424107/198834992-a5b1a6fc-9044-47ab-8a8d-2406903bfbcb.png)

## (b) 예측제곱합(PRESS:predict sum of squares)
- 모형의 예측력을 통해 평가

![](https://user-images.githubusercontent.com/77424107/198835166-84c7ea64-f5f0-4385-84f7-3ffa821f2ae0.png)

## (c) 예측결정계수(predicted R^2)
- PRESS를 통해 정의
- PRESS보다 더 직관적으로 해석 가능
- PRESS와 더불어 데이터셋을 **훈련용과 검증용으로 나누지 않고 모형의 예측력 비교할 수 있어 유용**
- PRESS와 예측결정계수는 모형추정에 포함되지 않은 자료를 이용하여 계산되므로 과적합 방지에 도움.

![](https://user-images.githubusercontent.com/77424107/198835317-23d43298-84f1-4a36-81d4-47a5f7c8f16a.png)

### ❗ 과적합
- 모형적합에 사용된 데이터에 대해서는 우수한 적합을 제공하지만, 새로운 관측값에 대해서는 유용한 적합을 보이지 못하는 것

## 2.2.3 교차타당법(cross-validation method)
- 데이터셋을 모형구축에 사용될 훈련용 셋과 예측력 평가에 사용될 평가용 셋으로 나누어 모형을 평가
- 데이터 양이 충분히 많은 경우 : 두 데이터셋 비율을 50:50으로 랜덤하게 나누어 적용

### ✅ K-중첩(fold) 교차타당법
- 데이터 양이 충분하지 않은 경우 
- 전체 데이터 셋을 동일한 크기의 K 조각으로 나누기
- 이 가운데 한 조각을 제외한 나머지 K-1 조각으로 모형을 구축
- 남겨둔 한 조각에 대해 예측 수행
- 남겨지는 조각을 바꿔가며 이 절차를 K번 반복
- 각 조각에 대한 제곱 예측오차를 더하여 교차타당법의 측도로 사용

### ✅ LOO(Leave-one-out) 교차타당법
- K-중첩 교차타당법에서 K=n인 경우
- 한 개의 데이터만 남기고 모형을 구축한 후 남겨진 한 개를 추정하는 과정을 반복
- 계산량 많아질 수 있음
- 예측오차의 추정치는 PRESS와 동일

## 2.2.4 데이터마이닝에서 모형 평가
- 보통 훈련용(train) 자료에 의해 구축된 모형을 검증용(test) 자료에 대해 적용하여 평가

### ✅ 이진 반응변수의 경우
- 정오분류표 사용
- 민감도 = 재현율
- 정확도 = True로 예측한 관측치 중 실제값이 True인 정도

![](https://user-images.githubusercontent.com/77424107/198835666-0ec04c5d-0037-46dc-af65-08261c98eb13.png)

![](https://user-images.githubusercontent.com/77424107/198835697-13c22cc2-225a-46e5-bf15-73f3838aa467.png)

### ✅ 연속형 반응변수의 경우
![](https://user-images.githubusercontent.com/77424107/198835933-98c93683-c3d4-4d7f-9ba6-56f41798f7e6.png)

- 평균절대백분위오차(MAPE)

![](https://blog.kakaocdn.net/dn/oKnA8/btqTLwTtjv2/stDS2lqsGmodIP7QKIMRpk/img.jpg)

### ✅ 모형선택을 위한 비교 방법

#### 1️⃣ 신뢰구간을 이용하는 방법
- 두 개의 예측모형 간 비교할 때
- 각 모형에 대해 k-중첩 교차타당도 방법을 수행한 평균 오차율을 추정하고, 이를 이용하여 오차율(=1-정확도)의 차이에 대한 신뢰구간을 구하여 비교하는 방법

#### 2️⃣ ROC(Receiver Operating Characteristic) 그래프
- 로지스틱 회귀 또는 베이즈 분류의 사후확률처럼 연속형의 값으로 주어질 때 유용
- 검증용 자료에 대해 예측값을 내림차순으로 정렬한 뒤, 분류를 위해 기준값을 선택하면 정오분류표를 얻게 됨
- 기준값을 0->1로 변화시키면서 해당 정오분류표로부터 **(1-특이도)와 민감도** 값을 구하고 이를 각각 x, y 좌표 상에 연결하여 그린 것
- ROC 곡선 아래 쪽 면적 = c-통계량 = AUC(area under the ROC curve) : 클수록 모형 성능이 우수

![](https://user-images.githubusercontent.com/77424107/198836274-977f1762-3ed8-4a75-8153-8d65fd38e19c.png)

### ✅ 그 외
- 검증용 자료에 기반한 모형평가 = 예비법(holdout method)
- 교차타당법, 붓스트랩
