---   
layout: post  
title: "[정보처리기사] 실기 2장. 데이터 입출력 구현"
date: 2022-10-06
excerpt: "정보처리기사 실기 2장 정리한 내용입니다."
tag:
- 정처기
comments: true
--- 

# SECTION 31. 데이터 전환

---

## 1. 데이터 전환
- 운영 중인 기존 정보 시스템에 축적되어 있는 데이터를 추출하여 새로 개발할 정보 시스템에서 운영할 수 있도록 변환 후 적재하는 일련의 과정
- ETL(추출, 변환, 적재) 과정
- = 데이터 이행 = 데이터 이관

## 2. 데이터 전환 계획서
- 데이터 전환 작업에 필요한 모든 계획을 기록하는 문서
- 주요 항목 : 데이터 전환 개요, 데이터 전환 대상 및 범위, 데이터 전환 환경 구성, 데이터 전환 조직 및 역할, 데이터 전환 일정, 데이터 전환 방안, 데이터 정비 방안, 비상 계획, 데이터 복구 대책

# SECTION 32. 데이터 검증

---

## 1. 데이터 검증

- 원천 시스템의 데이터를 목적 시스템의 데이터로 전환하는 과정이 정상적으로 수행되었는지 여부를 확인하는 과정

## 2. 검증 방법에 따른 분류
- 로그 검증 : 데이터 전환 과정에서 작성하는 추출, 전환, 적재 로그 검증
- 기본 항목 검증 : 로그 외에 별로로 요청된 항목에 대해 검증
- 응용 프로그램 검증 : 응용 프로그램 통한 데이터 정합성 검증
- 응용 데이터 검증 : 규칙을 기준으로 데이터 전환의 정합성 검증
- 값 검증

## 3. 검증 단계에 따른 분류

|검증 단계|목적|검증 방법|
|----|-------------|----|
|추출|원천 시스템 데이터에 대한 정합성 확인|로그 검증|
|전환|매핑 정의서에 정의된 내용이 정확히 반영되었는지 확인 및 매핑 정의서 오류 여부 확인|로그 검증|
|DB 적재|SAM 파일을 적재하는 과정에서 발생할 수 있는 오류나 데이터 누락 여부 확인|로그 검증|
|DB 적재 후|적재 완료 후 정합성 확인|기본 항목 검증|
|전환 완료 후|데이터 전환 완료 후 추가 검증 과정을 통해 데이터 전환의 정합성 검증|응용 프로그램 검증, 응용 데이터 검증|

# SECTION 33. 오류 데이터 측정 및 정제

---

## 1. 오류 데이터 측정 및 정제
- 고품질 데이터를 운영 및 관리하기 위해 수행
- 절차 : 데이터 품질 분석 -> 오류 데이터 측정 -> 오류 데이터 정제

### ✔️ 오류 데이터 측정 및 정제 절차
- 데이터 품질 분석 : 오류 데이터를 찿기 위해 원천 및 목적 시스템 데이터의 정합성 여부 확인
- 오류 데이터 측정 : 정상 데이터와 오류 데이터 수를 측정하여 오류 관리 목록 작성
- 오류 데이터 정제 : 오류 관리 목록의 각 항목 분석하여 원천 데이터 정제하거나 전환 프로그램 수정

## 2. 오류 상태
- Open : 오류만 보고되고 분석되지 않음
- Assigned : 오류의 영향 분석 및 수정을 위해 개발자에게 오류를 전달한 상태
- Fixed : 개발자가 오류를 수정한 상태
- Closed : 수정된 오류를 테스트 했을 때 오류가 발생되지 않은 상태
- Deferred : 오류 수정 연기한 상태
- Clarified/Classified : 보고된 오류를 관련자들이 확인했을 때 오류가 아니라고 확인된 상태

## 3. 데이터 정제요청서
- 데이터 정제와 관련된 전반적인 내용을 문서로 작성한 것
- 오류 관리 목록을 기반으로 데이터 정제 요건 목록을 작성하고 이 목록의 항목별로 데이터 정제요청서를 작성

## 4. 데이터 정제보고서
- 정제된 원천 데이터가 정상적으로 정제되었는지 확인한 결과를 문서로 작성한 것
- 정제 요청 데이터와 정제된 데이터 항목을 눈으로 직접 비교하여 확인

# SECTION 34. 데이터베이스 개요

---

## 1. 데이터 저장소
- 데이터들을 논리적인 구조로 조직화하거나, 물리적인 공간에 구축한 것
- 논리 데이터저장소 : 데이터 및 데이터 간 연관성, 제약조건 식별하여 논리적인 구조로 조직화한 것
- 물리 데이터저장소 : 논리 데이터저장소를 소프트웨어가 운용될 환경의 물리적 특성을 고려하여 실제 저장장치에 저장한 것

## 2. 데이터베이스
- 공동으로 사용될 데이터를 중복을 배제하여 통합하고, 저장장치에 저장하여 항상 사용할 수 있도록 운영하는 운영 데이터

### ✔️ 데이터 베이스 구분
- 통합된 데이터(Integrated Data) : 자료의 중복을 배제한 데이터 모임
- 저장된 데이터(Stored Data) : 컴퓨터가 접근할 수 있는 저장 매체에 저장된 자료
- 운영 데이터(Operational Data) : 조직 고유의 업무를 수행하는 데 반드시 필요한 자료
- 공용 데이터(Shared Data) : 여러 응용 시스템들이 공동으로 소유하고 유지하는 자료

## 3. DBMS(DataBase Management System, 데이터베이스 관리 시스템)
- 사용자의 요구에 따라 정보를 생성해주고, 데이터베이스를 관리해주는 소프트웨어
- 기존의 파일 시스템이 갖는 데이터의 종속성과 중복성 문제를 해결하기 위해 제안된 시스템

### ✔️ 필수 기능 3가지
- 정의 기능 : 데이터의 형과 구조에 대한 정의, 이용 방식, 제약 조건 등을 명시
- 조작 기능 : 데이터 검색, 갱신, 삽입, 삭제 등을 위해 인터페이스 수단 제공
- 제어 기능 : 데이터의 무결성, 보안, 권한 검사, 병행 제어를 제공

## 4. 데이터의 독립성
- 논리적 독립성 : 응용 프로그램과 데이터베이스를 독립, 데이터의 논리적 구조를 변경시켜도 응용프로그램은 영향받지 않음
- 물리적 독립성 : 응용 프로그램과 보조기억장치 같은 물리적 장치를 독립시킴으로써, 디스크를 추가 및 변경하더라도 응용 프로그램은 영향받지 않음

## 5. 스키마
- 데이터베이스 구조와 제약조건에 관한 전반적인 명세를 기술

### ✔️ 스키마 종류
- 외부 스키마 : 사용자나 응용 프로그래머가 각 개인의 입장에서 필요로 하는 데이터베이스의 논리적 구조를 정의한 것
- 개념 스키마 : 데이터베이스의 전체적인 논리적 구조, 모든 응용 프로그램이나 사용자들이 필요로 하는 데이터를 종합한 조직 전체의 데이터베이스로, 하나만 존재
- 내부 스키마 : 물리적 저장장치 입장에서 본 데이터베이스 구조, 실제로 저장될 레코드 형식과 저장 데이터의 표현 방법 및 내부 레코드의 물리적 순서 등을 나타냄

# SECTION 35. 데이터베이스 설계

---

## 1. 데이터베이스 설계
- 사용자의 요구를 분석하여 데이터베이스 구조에 맞게 변형한 후 DBMS로 데이터베이스를 구현하여 일반 사용자들이 사용하게 하는 것

## 2. 데이터베이스 설계시 고려사항
- 무결성 : 삽입, 삭제, 갱신 등의 연산 후에도 데이터베이스에 저장된 데이터는 제약 조건을 항상 만족해야 함
- 일관성 : 데이터베이스에 저장된 데이터 사이나, 특정 질의에 대한 응답이 처음부터 끝가지 변함없어야 함
- 회복 : 장애가 발생했을 때 장애 발생 직전 상태로 복구할 수 있어야 함
- 보안 : 데이터의 노출 또는 변경 및 손실로부터 보호할 수 있어야 함
- 효율성 : 응답시간 단축, 시스템 생산성, 저장공간 최적화 등이 가능해야 함
- 데이터베이스 확장 : 데이터베이스 운영에 영향 주지 않으면서 지속적으로 데이터 추가가 가능해야 함

## 3. 데이터베이스 설계 순서

### 3-1. 요구 조건 분석
- 요구 조건 명세서 작성
- 데이터베이스를 사용할 사람들로부터 필요한 용도를 파악하는 것

### 3-2. 개념적 설계(종보 모델링, 개념화)
- 개념 스키마, 트랜잭션 모델링, E-R 모델(요구 조건 명세를 DBMS에 독립적인 E-R 다이어그램으로 작성)
- 현실 세계에 대한 인식을 추상적 개념으로 표현하는 과정
- DBMS에 독립적인 개념 스키마 설계

### 3-3. 논리적 설계(데이터 모델링)
- 목표 DBMS에 맞는 논리 스키마 설계, 트랜잭션 인터페이스 설계
- 현실 세계에서 발생하는 자료를 물리적 저장장치에 저장할 수 있도록 변환하기 위해 **특정 DBMS가 지원하는 논리적 자료 구조로 변환(mapping)시키는 과정**
- 개념 세계의 데이터를 필드로 기술된 데이터 타입과 데이터 타입들 간 관계로 표현되는 논리적 구조의 데이터로 모델화
- 개념 스키마 평가 및 정제, DBMS에 따라 서로 다른 논리적 스키마를 설계하는 단계
- 트랜잭션의 인터페이스 설계

### 3-4. 물리적 설계(데이터 구조화)
- 목표 DBMS에 맞는 물리적 구조의 데이터로 변환
- 논리적 구조로 표현된 데이터를 물리적 저장장치에 저장할 수 있는 물리적 구조의 데이터로 변환하는 과정
- 다양한 데이터베이스 응용에 대해 처리 성능을 얻기 위해 데이터베이스 파일의 저장 구조 및 액세스 경로를 결정

### 3-5. 데이터베이스 구현
- 목표 DBMS의 DDL(데이터 정의어)로 데이터베이스 생성, 트랜잭션 작성
- 사용하려는 특정 DBMS의 DDL을 이용하여 데이터베이스의 스키마를 기술한 후 컴파일하여 빈 데이터베이스 파일을 만든다.
- 응용 프로그램을 위한 트랜잭션 작성
- 데이터베이스 접근을 위한 응용 프로그램 작성

# SECTION 36. 데이터 모델의 개념

---

## 1. 데이터 모델
- **현실 세계의 정보들을 컴퓨터에 표현하기 위해서 체계적으로 표현한 개념적 모형**
- 데이터, 데이터의 관계, 데이터의 의미 및 일관성, 제약 조건 등을 기술하기 위한 개념적 도구들로 구성됨
- DB 설계 과정에서 데이터 구조를 논리적으로 표현하기 위해 지능적 도구로 사용됨
- **데이터 모델 구성 요소** : 개체, 속성, 관계
- **데이터 모델 종류** : 개념적 데이터 모델, 논리적 데이터 모델, 물리적 데이터 모델
- **데이터 모델에 표시할 요소** : 구조, 연산, 제약 조건

## 2. 개념적 데이터 모델
- **현실 세계에 대한 인간의 이해를 돕기 위해 현실 세계에 대한 인식을 추상적 개념으로 표현하는 과정**
- **속성**들로 기술된 개체 타입과 이 개체 타입들 간 관계를 이용하여 현실세계 표현
- 현실 세계에 존재하는 개체를 인간이 이해할 수 있는 정보 구조로 표현하므로 **정보 모델**이라고도 함.
- 대표적인 개념적 모델 : E-R 모델

## 3. 논리적 데이터 모델
- **개념적 구조를 컴퓨터 세계의 환경에 맞도록 변환하는 과정**
- **필드**로 기술된 데이터 타입과 이 데이터 타입들 간 관계를 이용하여 현실세계 표현
- 단순히 데이터 모델이라고 하면 논리적 데이터 모델을 의미
- 특정 DBMS는 특정 논리적 데이터 모델 하나만 선정하여 사용
- 데이터 간 관계를 어떻게 표현하느냐에 따라 관계 모델, 계층 모델, 네트워크 모델로 구분

## 4. 데이터 모델에 표시할 요소
- 구조 : 논리적으로 표현된 개체 타입들 간 관계, 데이터 구조 및 정적 성질 표현
- 연산 : 실제 데이터를 처리하는 작업에 대한 명세, 데이터베이스를 조작하는 기본 도구
- 제약조건(Constraint) : DB에 저장될 수 있는 실제 데이터의 논리적 제약 조건

# SECTION 37. 데이터 모델의 구성 요소

---

## 1. 개체(Entity)
- 데이터베이스에 표현하려는 것, 사람이 생각하는 개념이나 정보 단위 같은 현실 세계의 대상체
- 실세계에 독립적으로 존재하는 유형, 무형의 정보로서 서로 연관된 몇 개의 속성으로 구성
- 독립적으로 존재하거나 그 자체로서도 구별 가능하며, 유일한 식별자에 의해 식별
- 다른 개체와 하나 이상의 관계가 있다.

### ✔️ 구성 요소
- 속성 : 개체가 가지고 있는 특성
- 개체 타입(레코드 타입) : 속성으로만 기술된 개체의 정의
- 개체 인스턴스 : 개체를 구성하고 있는 각 속성들이 값을 가져 하나의 개체를 나타내는 것, = 개체 어커런스(Occurrence)
- 개체 세트 : 개체 인스턴스의 집합

## 2. 속성(Attribute)
- 데이터베이스를 구성하는 가장 작은 논리적 단위
- 파일 구조 상 데이터 항목 또는 데이터 필드에 해당
- 속성은 개체를 구성하는 항목으로 개체의 특성을 기술
- 디그리 = 차수 : 속성의 수
- 속성은 속성의 특성과 개체 구성 방식에 따라 분류

## 3. 속성의 특성에 따른 분류

|분류|내용|
|---|-----|
|기본 속성(Basic Attribute)|업무 분석을 통해 정의한 속성, 일반적임, 업무상 코드로 정의한 속성은 기본속성에서 제외|
|설계 속성(Designed Attribute)|원래 업무상 존재하지 않고 설계 과정에서 도출, 데이터 모델링을 위해 업무를 규칙화하려고 속성을 새로 만들거나 변형하여 정의하는 속성|
|파생 속성(Derived Attribute)|다른 속성으로부터 계산이나 변형 등 영향을 받아 발생, 되도록 적은 수를 정의하는 것이 좋음|

- ex) 자동차 -> 기본 속성 : 자동차명, 제조일, 연비 / 설계 속성 : 자동차코드 / 파생 속성 : 계산값

## 4. 속성의 개체 구성 방식에 따른 분류

- 기본키 속성 : 개체를 유일하게 식별할 수 있는 속성
- 외래키 속성 : 다른 개체와의 관계에서 포함된 속성
- 일반 속성 : 개체에 포함되어 있고 기본키, 외래키에 포함되지 않은 속성

## 5. 관계
- 개체와 개체 사이의 논리적 연결
- 개체 간 관계, 속성 간 관계가 있음

## 6. 관계의 형태
- 일 대 일 
- 일 대 다
- 다 대 다

## 7. 관계의 종류
- 종속 관계(Dependent) : 두 개체 사이의 주종 관계, 식별 관계와 비식별 관계가 있음
- 중복 관계(Redundant) : 두 개체 사이에 2번 이상의 종속 관계가 발생하는 관계
- 재귀 관계(Recursive) : 개체가 자기 자신과 관계를 갖는 것, = 순환 관계
- 배타 관계(Exclusive) : 개체의 속성이나 구분자를 기준으로 개체의 특성을 분할하는 관계, 배타 AND 관계와 배타 OR 관계로 구분

# SECTION 38. 식별자(Identifier)

---

## 1. 식별자
- 하나의 개체 내에서 각각의 인스턴스를 유일하게 구분할 수 있는 구분자
- 모든 개체는 한 개 이상의 식별자를 반드시 가져야 함

## 2. 식별자의 분류

### 2-1. 대표성 여부
- 주식별자 : 개체를 대표하는 유일한 식별자
- 보조 식별자 : 주 식별자를 대신하여 개체를 식별할 수 있는 속성

### 2-2. 스스로 생성 여부
- 내부 식별자 : 개체 내에서 스스로 만들어지는 식별자
- 외부 식별자 : 다른 개체와의 관계에 의해 외부 개체의 식별자를 가져와 사용하는 식별자

### 2-3. 단일 속성 여부
- 단일 식별자 : 주 식별자가 한 가지 속성으로만 구성
- 복합 식별자 : 주 식별자가 두 개 이상의 속성으로 구성된 식별자

### 2-4. 대체 여부
- 원조 식별자 : 업무에 의해 만들어지는 가공되지 않은 원래의 식별자, = 본질 식별자
- 대리 식별자 : 주 식별자의 속성이 두 개 이상인 경우 속성들을 하나로 묶어 사용하는 식별자, = 인조 색별자

## 3. 후보 식별자
- 개체에서 각 인스턴스를 유일하게 식별할 수 있는 속성 또는 속성 집합
- 하나의 개체에는 한 개 이상의 후보 식별자가 존재할 수 있으며, 이 중 개체의 대표성을 나타내는 식별자를 주 식별자로, 나머지는 보조 식별자로 지정

## 4. 주 식별자의 특징
- 유일성 : 개체 내 모든 인스턴스들을 주 식별자에 의해 유일하게 구분되어야 함
- 최소성 : 유일성을 만족시키기에 필요한 최소한의 속성으로만 구성되어야 함
- 불변성 : 주 식별자가 특정 개체에 한 번 지정되면 그 식별자는 변하지 않아야 함
- 존재성 : 주 식별자가 지정되면 식별자 속성에 반드시 데이터 값이 존재해야 함

# SECTION 39. E-R(개체-관계) 모델

---

## 1. E-R(Entity-Relationship, 개체-관계) 모델
- 개체 간 관계를 기본 요소로 이용하여 현실 세계의 무질서한 데이터를 개념적인 논리 데이터로 표현하기 위한 방법
- 1976년 피터 챈에 의해 제안되고 기본적인 구성 요소가 정립됨
- 개념적 데이터 모델의 가장 대표적인 것
- 개체 타입과 이들 간 관계 타입을 이용하여 현실 세계를 개념적으로 표현
- 데이터를 개체, 관계, 속성으로 묘사

## 2. E-R 다이어그램 종류
- 사각형 : 개체 타입
- 마름모 : 관계 타입
- 타원 : 속성
- 이중 타원 : 다중값 속성(복합 속성)
- 밑줄 타원 : 기본키 속성
- 복수 타원 : 복합 속성 ex. 성명은 성과 이름으로 구성됨
- 관계 : 개체 간 관계에 대한 대응수를 선 위에 기술
- 선, 링크 : 개체 타입과 속성을 연결

# SECTION 40. 관계형 데이터베이스의 구조 / 관계형 데이터 모델

---

## 1. 관계형 데이터베이스
- 2차원적인 표를 이용해서 데이터 상호 관계를 정의하는 데이터베이스
- 1970년 IBM 코드에 의해 처음 제안
- 개체와 관계를 모두 릴레이션이라는 표로 표현하므로 개체를 표현하는 개체 릴레이션과 관계를 표현하는 관계 릴레이션이 존재
- 장점 : 간결, 보기 편리, 다른 데이터베이스로의 변환 용이
- 단점 : 성능이 다소 떨어짐

## 2. 관계형 데이터베이스 릴레이션 구조
- 릴레이션 : 데이터들을 표 형태로 표현한 것
- 구조를 나타내는 릴레이션 스키마와 실제 값들인 릴레이션 인스턴스로 구성됨

## 3. 튜플
- 릴레이션을 구성하는 각각의 행
- 속성의 모임으로 구성
- 파일구조에서 레코드와 같은 의미
- 카디널리티, 기수, 대응수 = 튜플의 수

## 4. 속성
- 데이터베이스를 구성하는 가장 작은 논리적 단위
- 파일 구조 상 데이터 항목 또는 필드에 해당
- 개체의 특성을 기술
- 디그리, 차수 = 속성의 수

## 5. 도메인
- 하나의 애트리뷰트가 취할 수 있는 타입의 원자값들의 집합
- 실제 애트리뷰트 값이 나타날 때 그 값이 합법 여부를 시스템이 검사하는데에도 이용됨

## 6. 릴레이션 특징
- 한 릴레이션에는 똑같은 튜플이 포함될 수 없다.
- 튜플 사이에는 순서가 없다.
- 튜플의 삽입, 삭제 등 작업으로 인해 시간에 따라 변화
- 속성들 간 순서는 중요하지 않다
- 속성의 명칭은 유일해야 하지만, 속성을 구성하는 값은 동일 값이 있을 수 있다.
- 튜플을 유일하게 식별하기 위해 속성들의 부분집합을 키로 설정
- 속성 값은 논리적으로 더 이상 쪼갤 수 없는 원자값만을 저장

## 7. 관계형 데이터 모델
- 2차원적인 표를 이용해서 데이터 상호 관계를 정의하는 DB구조
- 가장 널리 사용되는 모델
- 테이블들을 하나의 DB로 묶어서 테이블 내에 있는 속성들 간 관계를 설정하거나 테이블 간 관계를 설정하여 이용
- 기본 키와 이를 참조하는 외래키로 데이터 간 관계 표현
- 계층 모델과 망 모델의 복잡한 구조를 단순화시킨 모델
- 대표적 언어 : SQL
- 관계를 자유롭게 표현 가능

# SECTION 41. 관계형 데이터베이스 제약 조건 - 키

---

## 1. 키
- 조건에 만족하는 튜플을 찾거나 순서대로 정렬할 때 기준이 되는 속성
- 종류 : 후보키, 기본키, 대체키, 슈퍼키, 외래키

## 2, 후보키(Candidate Key)
- 속성들 중에서 튜플을 유일하게 식별하기 위해 사용되는 속성들의 부분집합
- 기본 키로 사용할 수 있는 속성들
- 유일성, 최소성을 모두 만족시켜야 함

## 3. 기본키(Primary Key)
- 후보키 중에서 특별히 선정된 주키(Main Key)
- 중복된 값을 가질 수 없음
- 한 릴레이션에서 특정 튜플을 유일하게 구분 가능
- NULL 값을 가질 수 없음

## 4. 대체키(Alternative Key)
- 후보키가 둘 이상일 때 기본키를 제외한 나머지 후보키를 의미
- 보조키라고도 함

## 5. 슈퍼키
- **한 릴레이션 내에 있는 속성들의 집합으로 구성된 키**
- 릴레이션에 있는 모든 튜플에 대해 유일성은 만족하지만 최소성은 만족시키지 못함
- 슈퍼키로 구성된 속성의 집합과 동일한 값은 나타나지 않음

## 6. 외래키
- 다른 릴레이션의 기본키를 참조하는 속성 또는 속성들의 집합
- 외래키로 지정되면 참조 릴레이션의 기본키에 없는 값은 입력 불가

# SECTION 42. 관계형 데이터베이스 제약 조건 - 무결성

---

## 1. 무결성(Integrity)
- 데이터베이스에 저장된 데이터 값과 현실 세계의 실제값이 일치하는 정확성
- 무결성 제약 조건은 데이터베이스에 들어 있는 데이터의 정확성을 보장하기 위해 부정확한 자료가 데이터베이스 내에 저장되는 것을 방지하기 위한 제약 조건

## 2. 무결성 종류
- 개체 무결성 : 기본키를 구성하는 어떤 속성도 Null 값이나 중복값을 가질 수 없음
- 참조 무결성 : 외래키 값은 Null이거나 참조 릴레이션의 기본키 값과 동일해야 함
- 도메인 무결성 : 주어진 속성 값이 정의된 도메인에 속한 값이어야 함
- 사용자 정의 무결성 : 사용자가 정의한 제약조건에 속성들이 만족되어야 함
- NULL 무결성 : 특정 속성 값이 NULL이 될 수 없도록 하는 규정
- 고유 무결성 : 특정 속성에 대해 각 튜플이 갖는 속성값들이 서로 달라야 한다는 규정
- 키 무결성 : 하나의 릴레이션에는 적어도 하나의 키가 존재해야 함
- 관계 무결성 : 어느 한 튜플의 삽입 가능 여부 또는 한 릴레이션과 다른 릴레이션의 튜플들 사이의 관계에 대한 적절성 여부를 지정한 규정

## 3. 데이터 무결성 강화
- 데이터 품질에 직접적 영향을 미치므로 데이터 특성에 맞는 적절한 무결성 정의 및 강화 필요

### ✔️ 애플리케이션, 데이터베이스 트리거, 제약 조건 이용하여 강화 가능
- 애플리케이션 : 데이터 생성, 수정, 삭제 시 무결성 조건을 검증하는 코드를 프로그램 내에 추가
- 데이터베이스 트리거 : 트리거 이벤트에 무결성 조건을 실행하는 절자형 SQL 추가
- 제약 조건 : 데이터베이스에 제약조건 설정하여 무결성 유지

# SECTION 43. 관계대수 및 관계해석

---

## 1. 관계대수
- 원하는 정보와 그 정보를 검색하기 위해서 어떻게 유도하는가를 기술하는 절차적 언어
- 연산자와 연산규칙 제공, 피연산자와 연산 결과가 모두 릴레이션
- 질의에 대한 해를 구하기 위해 수행해야 할 연산의 순서를 명시
- 관계 데이터베이스에 적용하기 위해 특별히 개발한 **순수 관계 연산자**와 수학적 집합 이론에서 사용하는 **일반 집합 연산자**가 있다.

## 2. 순수 관계 연산자

![](https://blog.kakaocdn.net/dn/cPbvcR/btrqmp8bIIP/Sz997AWS0FsMb59jwICOd1/img.jpg)
<center>그림 출처 : https://mi-nya.tistory.com/96</center>

## 3. 일반 집합 연산자
- 수학적 집합 이론에서 사용하는 연산자
- 합집합, 교집합, 차집합을 처리하기 위해서는 합병 조건 만족해야 함

![](https://hyeonukdev.github.io/images/%EC%A0%95%EB%B3%B4%EC%B2%98%EB%A6%AC%EA%B8%B0%EC%82%AC/0513_05.png)
<center>그림 출처 : https://hyeonukdev.github.io/2020/05/13/Engineer_Information_Processing</center>

## 4. 관계해석(Relational Calculus)
- 관계 데이터의 연산을 표현하는 방법
- 관계 데이터 모델의 제안자인 코드가 수학의 Predicate Calculus(술어 해석)에 기반을 두고 관계 데이터베이스를 위해 제안
- 원하는 정보가 무엇이라는 것만 정의하는 비절차적 특성
- 원하는 정보를 정의할 때는 계산 수식을 사용

# SECTION 44. 이상 / 함수적 종속

---

## 1. 이상(Anomaly)
- 테이블에서 데이터 중복이 발생하고, 이 중복으로 인해 문제가 발생하는 현상
- 종류 : 삽입이상, 삭제 이상, 갱신 이상

### 1-1. 삽입 이상(Insertion Anomaly)
- 테이블에 데이터를 삽입할 때 의도와는 상관 없이 원하지 않는 값들로 인해 삽입할 수 없게 되는 현상

### 1-2. 삭제 이상(Deletion Anomaly)
- 한 튜플을 삭제할 때 의도와는 상관없는 값들도 함께 삭제되는, 연쇄 삭제가 발생하는 현상

### 1-3. 갱신 이상(Update Anomaly)
- 테이블에서 튜플에 있는 속성 값을 갱신할 때 일부 튜플의 정보만 갱신되어 정보에 불일치성이 생기는 현상

## 2. 함수적 종속(Functional Dependency)
- 속성 X의 값 각각에 대해 시간에 관계없이 항상 속성 Y 값이 오직 하나만 연관되어 있을 때 Y는 X에 함수적 종속 or X가 Y를 함수적을 결정 or X -> Y
- 데이터의 의미를 표현
- 현실세계를 표현하는 제약 조건이 되는 동시에 데이터베이스에서 항상 유지되어야 할 조건
- X -> Y에서 X를 결정자라고 하고, Y를 종속자라고 함.
- 완전 함수적 종속이 아닌 경우 부분 함수적 종속이라고 함

# SECTION 45. 정규화(Normalization)

---

## 1. 정규화
- 테이블의 속성이 상호 종속적인 관계를 갖는 특성을 이용하여 테이블을 무손실 분해하는 과정
- 가능한 한 중복을 제거하여 삽입, 삭제, 갱신 이상의 발생 가능성 줄이는 것

## 2. 정규화 과정

### 2-1. 제 1정규형(1NF, First Normal Form)
- 모든 속성의 도메인이 원자 값만으로 되어 있음

### 2-2. 제 2정규형(2NF)
- 테이블 R이 제 1정규형이고, 기본키가 아닌 모든 속성이 기본키에 대하여 완전 함수적 종속을 만족하는 정규형

### 2-3. 제 3정규형(3NF)
- 테이블 R이 제 2정규형이고 기본키가 아닌 모든 속성이 기본키에 대해 이행적 함수적 종속을 만족하지 않는 정규형

### 2-4. BCNF
- 테이블 R에서 모든 결정자가 후보키인 정규화
- 제 3정규형에 후보키가 여러 개 존재하고, 이런 후보키들이 서로 중첩되어 나타나는 경우 적용 가능

### 2-5. 제 4정규형
- 테이블 R에 다중값종속(MDV;Multi Valued Dependency) A->->B가 존재할 경우 R의 모든 속성이 A에 함수적 종속 관계를 만족하는 정규형

### 2-6. 제 5정규형
- 테이블 R의 모든 조인 종속이 R의 후보키를 통해서만 성립되는 정규형

## 3. 정규화 과정 정리

![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS6L4CVwO0giGLh8IEUoWNLz2njfFufpq_RAtvABMe64gddYvvx5f7mrRkAvqM-tbbpVmw&usqp=CAU)

출처 : velog.io/@jihun333/데이터베이스정규화Normalization

# SECTION 46. 반정규화(Denormalization)

---

## 1. 반정규화
- 정규화된 데이터 모델을 의도적으로 통합, 중복, 분리하여 정규화 원칙을 위배하는 행위
- 반정규화를 수행하면 시스템 성능이 향상되고 관리 효율성은 증가하지만 데이터의 일관성 및 정합성이 저하될 수 있음
- 과도한 반정규화는 오히려 성능을 저하
- 방법 : 테이블 통합, 테이블 분할, 중복 테이블 추가, 중복 속성 추가

## 2. 테이블 통합
- 두 개의 테이블이 조인되어 사용되는 경우가 많을 경우 성능 향상을 위해 아예 하나의 테이블로 만들어 사용하는 것

### ✔️ 테이블 통합을 고려하는 경우
- 두 개의 테이블에서 발생하는 프로세스가 동일하게 자주 처리되는 경우
- 항상 두 개의 테이블을 이용하여 조회하는 경우

### ✔️ 테이블 통합의 종류
- 1:1 관계 테이블 통합
- 1:N 관계 테이블 통합
- 슈퍼타입/서브타입 테이블 통합

## 3. 테이블 분할
- 테이블을 수직 또는 수평으로 분할하는 것

### 3-1. 수평 분할
- 레코드 기준으로 테이블 분할
- 레코드 별 사용 빈도 차이가 큰 경우 사용 빈도에 따라 테이블 분할

### 3-2. 수직 분할
- 하나의 테이블에 속성이 너무 많을 경우 속성을 기준으로 테이블 분할
- 종류 : 갱신 위주의 속성 분할, 자주 조회되는 속성 분할, 크기가 큰 속성 분할, 보안을 적용해야 하는 속성 분할

## 4. 중복 테이블 추가
- 작업의 효율성 향상시키기 위해 테이블 추가

### ✔️ 중복 테이블 추가하는 경우
- 여러 테이블에서 데이터를 추출해서 사용해야 할 경우
- 다른 서버에 저장된 데이터를 이용해야 하는 경우

### ✔️ 중복 테이블 추가 방법
- 집계 테이블 추가 : 집계 데이터를 위한 테이블 생성하고 각 원본 테이블에 트리거를 설정하여 사용
- 진행 테이블 추가 : 이력 관리 등 목적으로 추가하는 테이블
- 특정 부분만을 포함하는 테이블의 추가 : 데이터가 많은 테이블의 특정 부분만을 사용하는 경우 해당 부분만으로 새로운 테이블 생성

## 5. 중복 속성 추가
- 조인해서 데이터를 처리할 때 데이터를 조회하는 경로를 단축하기 위해 자주 사용하는 속성을 하나 더 추가하는 것
- 중복 속성을 추가하면 데이터 무결성 확보가 어렵고, 디스크 공간이 추가로 필요

### ✔️ 중복 속성을 추가하는 경우
- 조인이 자주 발생하는 속성인 경우
- 접근 경로가 복잡한 속성인 경우
- 액세스의 조건으로 자주 사용되는 속성인 경우
- 기본키의 형태가 적절하지 않거나 여러 개 속성으로 구성된 경우

# SECTION 47. 시스템 카탈로그

---

## 1. 시스템 카탈로그
- 다양한 객체에 관한 정보를 포함한 시스템 데이터베이스
- 각 테이블은 사용자를 포함하여 DBMS에서 지원하는 모든 데이터 객체에 대한 정의나 명세에 관한 정보를 유지 관리하는 시스템 테이블
- 카탈로그들이 생성되면 데이터 사전에 저장되므로 좁은 의미로는 카탈로그를 데이터 사전이라고 함

## 2. 메타 데이터
- 시스템 카탈로그에 저장된 정보

### ✔️ 유형
- 데이터베이스 객체 정보 : 테이블, 인덱스, 뷰 등 구조 및 통계 정보
- 사용자 정보 : 아이디, 패스워드, 접근 권한 등
- 테이블 무결성 제약 조건 정보 : 기본키, 외래키, NULL 값 허용 여부 등
- 함수, 프로시저, 트리거 등에 대한 정보

## 3. 데이터 디렉터리
- 데이터 사전에 수록된 데이터에 접근하는 데 필요한 정보를 관리 유지하는 시스템
- 시스템 카탈로그는 사용자와 시스템 모두 접근 가능하지만 데이터 디렉터리는 시스템만 접근 가능

# SECTION 48. 데이터베이스 저장 공간 설계

---

## 1. 데이터베이스 저장 공간 설계
- 데이터를 저장하려면 테이블이나 컬럼 등 실제 데이터가 저장되는 공간을 정의해야 함
- 테이블 : 데이터베이스의 가장 기본적인 객체, 로우와 컬럼으로 구성, 데이터베이스의 모든 데이터는 테이블에 저장됨
- 테이블스페이스 : 테이블에 저장되는 논리적 영역, 한 개의 테이블스페이스에 한 개 이상의 테이블 저장 가능

## 2. 테이블 종류
- 일반 테이블 : 대부분 DBMS에서 표준 테이블로 사용되는 형태
- 클러스터디 인덱스 테이블 : 기본키나 인덱스키의 순서에 따라 데이터가 저장되는 테이블, 일반적인 인덱스를 사용하는 테이블에 비해 접근 경로가 단축됨
- 파티셔닝 테이블 : 대용량의 테이블을 작은 논리적 단위인 파티션으로 나눈 테이블
- 외부 테이블 : 데이터베이스에서 일반 테이블처럼 이용할 수 있는 외부 파일, 데이터베이스 내에 객체로 존재
- 임시 테이블 : 트랜잭션이나 세션별로 데이터 저장하고 처리할 수 있는 테이블, 임시 테이블에 저장된 데이터는 트랜잭션이 종료되면 삭제됨

# SECTION 49. 트랜잭션 분석 / CRUD 분석

---

## 1. 트랜잭션
- 하나의 논리적 기능을 수행하기 위한 작업의 단위 또는 한꺼번에 모두 수행되어야 할 일련의 연산들
- 데이터베이스 시스템에서 병행 제어 및 회복 작업 시 처리되는 작업의 논리적 단위로 사용됨
- 사용자가 시스템에 대한 서비스 요구 시 시스템이 응답하기 위한 상태 변환 과정의 작업 단위로 사용

## 2. 트랜잭션 특징
- Atomicity(원자성) : 트랜잭션의 연산은 데이터베이스에 모두 반영되도록 완료(Commit)되는지 아니면 전혀 반영되지 않도록 복구(Rollback)되어야 함
- Consistency(일관성) : 트랜잭션이 그 실행을 성공적으로 완료하면 언제나 일관성 있는 데이터베이스 상태로 변환
- Isolation(독립성, 격리성, 순차형) : 둘 이상의 트랜잭션이 동시에 병행 실행되는 경우 어느 하나의 트랜잭션 실행중에 다른 트랜잭션의 연산이 끼어들 수 없음
- Durability(영속성, 지속성) : 성공적으로 완료된 트랜잭션의 결과는 시스템이 고장나더라도 영구적으로 반영되어야 함

## 3. CRUD 분석
- 프로세스와 테이블 간 CRUD 매트릭스를 만들어서 트랜잭션을 분석하는 것
- CRUD 분석을 통해 많은 트랜잭션이 몰리는 테이블을 파악할 수 있으므로 디스크 구성 시 유용한 자료로 활용 가능

### ✔️ CRUD 매트릭스
- 2차원 형태의 표
- 행 : 프로세스
- 열 : 테이블
- 행과 열이 만나는 위치 : 프로세스가 테이블에 발생시키는 변화를 표시
- 각 셀에는 Create, Read, Update, Delete 앞 글자가 들어가며, 복수의 변화를 줄 때는 C > D > U > R 의 우선순위를 적용하여 한 가지만 적지만, 활용 목적에 따라 모두 기록 가능
- CRUD 매트릭스가 완성되었다면 C, R, U, D 중 어느 것도 적히지 않은 행과 열, C나 R이 없는 열을 확인하여 불필요하거나 누락된 테이블 또는 프로세스를 찾는다.

## 4. 트랜잭션 분석
- CRUD 매트릭스를 기반으로 테이블에 발생하는 트랜잭션 양을 분석하여 테이블에 저장되는 데이터의 양을 유추하고 이를 근거로 DB의 용량 산정 및 구조의 최적화
- 업무 개발 담당자가 수행
- 프로세스가 과도하게 접근하는 테이블을 확인할 수 있으며, 이러한 집중 접근 테이블을 여러 디스크에 분산 배치함으로써 디스크 입출력 향상을 통한 성능 향상을 가져올 수 있음

### ✔️ 트랜잭션 분석서
- 단위 프로세스와 CRUD 매트릭스를 이용하여 작성
- 구성 요소 : 단위 프로세스, CRUD 연산, 테이블명, 컬럼명, 테이블 참조 횟수, 트랜잭션 수, 발생 주기 등

# SECTION 50. 인덱스

---

## 1. 인덱스
- 데이터 레코드를 빠르게 접근하기 위해 <키 값, 포인터> 쌍으로 구성되는 데이터 구조
- 물리적 구조에 접근하는 방법 제공
- 파일 레코드에 빠르게 액세스 가능
- 레코드 삽입과 삭제가 수시로 일어나는 경우에는 인덱스 개수를 최소로 하는게 효율적

## 2. 인덱스 종류
- 트리 기반 인덱스 : 인덱스를 저장하는 블록들이 트리 구조를 이루고 있는 것
- 비트맵 인덱스 :  인덱스 컬럼의 데이터를 Bit 값인 0 또는 1로 변환하여 인덱스 키로 사용하는 방법
- 함수 기반 인덱스 : 컬럼 값 대신 특정 함수나 수식을 사용하여 산출된 값 이용
- 비트맵 조인 인덱스 : 다수의 조인된 객체로 구성된 인덱스
- 도메인 인덱스 : 개발자가 필요한 인덱스를 직접 만들어 사용하는 것

## 3. 클러스터드/넌클러스터드 인덱스
- 클러스터드 인덱스 : 인덱스 키의 순서에 따라 데이터가 정렬되어 저장되는 방식, 실제 데이터가 순서대로 저장되어 있어 인덱스를 검색하지 않아도 원하는 데이터를 빠르게 찾을 수 있음
- 넌클러스터드 인덱스 : 인덱스의 키 값만 정렬되어 있고 실제 데이터는 정렬되지 않는 방식, 데이터 삽입 및 삭제 발생 시 순서를 유지하기 위해 데이터를 재정렬해야 함

# SECTION 51. 뷰/클러스터

---

## 1. 뷰
- 하나 이상의 기본 테이블로부터 유도된 가상 테이블
- 저장장치 내에 물리적으로 존재하지 않지만, 사용자에게는 있는 것처럼 보임
- 뷰를 통해서 데이터를 접근하게 하면 뷰에 나타나지 않는 데이터를 안전하게 보호 가능
- 뷰가 정의된 기본 테이블이나 뷰를 삭제하면 그 테이블이나 뷰를 기초로 정의된 다른 뷰도 자동으로 삭제
- 정의할 때 : CREATE, 제거할 때 : DROP

## 2. 뷰 장단점
- 장점 : 논리적 데이터 독립성, 동일 데이터에 대해 동시에 여러 사용자의 상이한 응용이나 요구 지원, 사용자의 데이터 관리 간단하게 함, 접근 제어를 통한 자동 보안 제공
- 단점 : 독립적인 인덱스 가질 수 없음, 뷰의 정의 변경 불가, 뷰로 구성된 내용에 삽입 삭제 갱신 연산 제약

## 3. 클러스터
- 동일한 성격의 데이터를 동일한 데이터 블록에 저장하는 물리적 저장 방법
- 클러스터링된 테이블은 데이터 조회 속도를 향상시키나 입력, 수정, 삭제에 대한 작업 성능을 저하시킴
- 데이터 분포도가 넓을수록 유리
- 데이터 분포도가 넓은 테이블을 클러스터링 하면 저장 공간 절약 가능
- 처리 범위가 넓은 경우에는 단일 테이블 클러스터링을, 조인이 많이 발생하는 경우에는 다중 테이블 클러스터링을 사용

# SECTION 52. 파티션

---

## 1. 파티션
- 대용량의 테이블이나 인덱스를 작은 논리적 단위인 파티션으로 나누는 것
- 대용량 DB의 경우 몇 개의 중요한 테이블에만 집중되어 데이터가 증가되므로, 이런 테이블들을 작은 단위로 나눠 분산시키면 성능 저하를 방지할 뿐만 아니라 데이터 관리도 쉬워짐
- 데이터 처리는 테이블 단위로 이뤄지고, 데이터 저장은 파티션별로 수행됨

## 2. 파티션의 장단점

### 2-1. 장점
- 데이터 접근 시 액세스 범위를 줄여 쿼리 성능 향상
- 파티션별로 데이터가 분산되어 저장되므로 디스크 성능 향상됨
- 파티션별로 백업 및 복구 수행하므로 속도 빠름
- 데이터 가용성 향상됨
- 파티션 단위로 입출력을 분산시킬 수 있음

### 2-2. 단점
- 하나의 테이블을 세분화하여 관리하므로 세심한 관리가 요구됨
- 테이블 간 조인에 대한 비용이 증가
- 용량이 작은 테이블에 파티셔닝을 수행하면 오히려 성능이 저하됨

## 3. 파티션 종류

### 3-1. 범위 분할(Range Partitioning)
- 지정한 열 값을 기준으로 분할
- 예. 일별, 월별, 분기별 등

### 3-2. 해시 분할
- 해시 함수를 적용한 결과 값에 따라 데이터 분할
- 특정 파티션에 데이터가 집중되는 범위 분할의 단점을 보완한 것으로, **데이터를 고르게 분산할 때 유용**
- 특정 데이터가 어디에 있는지 판단 불가
- 고객번호, 주민번호 등과 같이 데이터가 고른 컬럼에 효과적

### 3-3. 조합 분할(Composite Partitioning)
- 범위 분할로 분할한 다음 해시 함수를 적용하여 다시 분할하는 방식
- 범위 분할한 파티션이 너무 커서 관리가 어려울 때 유용

# SECTION 53. 분산 데이터베이스 설계

---

## 1. 데이터베이스 용량 설계
- 데이터가 저장될 공간 정의
- 테이블에 저장될 데이터 양과 인덱스, 클러스터 등이 차지하는 공간 등을 예측하여 반영해야 함

### ✔️ 용량 설계의 목적
- 디스크의 저장 공간을 효과적으로 사용하고 확장성 및 가용성 높이기
- 디스크의 입출력 부하를 분산시키고 채널의 병목현상 최소화

## 2. 분산 데이터베이스 설계
- 논리적으로는 하나의 시스템에 속하지만 물리적으로는 네트워크를 통해 연결된 여러 개의 사이트에 분산된 데이터베이스
- 데이터의 처리나 이용이 많은 지역에 데이터베이스를 위치시킴으로써 데이터의 처리가 가능한 해당 지역에서 해결될 수 있도록 함
- 애플리케이션이나 사용자가 분산되어 저장된 데이터에 접근하게 하는 것을 목적으로 함

## 3. 분산 데이터베이스의 목표
- 위치 투명성(Location Transparency) : 액세스하려는 데이터베이스의 실제 위치를 알 필요 없이 단지 데이터베이스의 논리적인 명칭만으로 액세스 할 수 있음
- 중복 투명성(Replication Transparency) : 동일 데이터가 여러 곳에 중복되어 있더라도 사용자는 마치 하나의 데이터만 존재하는 것처럼 사용하고, 시스템은 자동으로 여러 자료에 대한 작업을 수행
- 병행 투명성(Concurrency Transparency) : 분산 데이터베이스와 관련된 다수의 트랜잭션들이 동시에 실현되더라도 그 트랜잭션의 결과는 영향을 받지 않음
- 장애 투명성(Failure Transparency) : 트랜잭션, DBMS, 네트워크, 컴퓨터 장애에도 불구하고 트랜잭션을 정확하게 처리

## 4. 분산 설계 방법
- 테이블 위치 분산 : 데이터베이스의 테이블을 각기 다른 서버에 분산시켜 배치하는 방법
- 분할 : 테이블의 데이터를 분할하여 분산시키는 것, 분할 규칙(완전성, 재구성, 상호 중첩 배제), 주요 분할 방법(수평 분할, 수직 분할)
- 할당 : 동일한 분할을 여러 개 서버에 생성하는 분산 방법, 중복이 없는 할당과 중복이 있는 할당 방법

# SECTION 54. 데이터베이스 이중화/서버 클러스터링

---

## 1. 데이터베이스 이중화
- 오류 발생 시 이를 복구하기 위해 동일한 데이터베이스를 복제하여 관리
- 데이터베이스가 항상 같은 상태를 유지하므로 DB에 문제가 발생하면 복제된 데이터베이스를 이용하여 즉시 해결 가능
- 여러 개 데이터베이스를 동시에 관리하므로 사용자가 수행하는 작업은 데이터베이스 이중화 시스템에 연결된 다른 데이터베이스에도 동일하게 적용
- 애플리케이션을 여러 개의 데이터베이스에서 분산 처리하므로 데이터베이스의 부하 줄일 수 있음
- 손쉽게 백업 서버를 운영 가능

## 2. 데이터베이스 이중화의 분류
- Eager 기법 : 트랜잭션 수행 중 데이터 변경이 발생하면 이중화된 모든 데이터베이스에 즉시 전달하여 변경 내용이 즉시 적용되도록 하는 기법
- Lazy 기법 : 트랜잭션 수행이 종료되면 변경 사실을 새로운 트랜잭션에 작성하여 각 데이터베이스에 전달되는 기법, 데이터베이스마다 새로운 트랜잭션이 수행되는 것으로 간주

## 3. 데이터베이스 이중화 구성 방법
- 활동-대기 방법 : 한 DB가 활성 상태로 서비스하고 있으면 다른 DB는 대기하고 있다가 활성 DB에 장애가 발생하면 대기 상태에 있던 DB가 자동으로 모든 서비스를 대신 수행, 구성 방법과 관리가 쉬워 많은 기업에서 이용
- 활동-활동 방법 : 두 개의 DB가 서로 다른 서비스를 제공하다가 한 쪽 DB에 문제가 생기면 나머지 다른 DB가 서비스를 제공, 두 DB가 모두 처리하므로 처리율이 높지만 구성 방법 및 설정이 복잡

## 4. 클러스터링
- 두 대 이상의 서버를 하나의 서버처럼 운영하는 기술
- 서버 이중화 및 공유 스토리지를 사용하여 서버의 고가용성을 제공

### ✔️ 종류
- 고가용성 클러스터링 : 하나의 서버에 장애가 발생하면 다른 노드가 받아 처리하여 서비스 중단을 방지, 일반적으로 언급되는 클러스터링
- 병렬 처리 클러스터링 : 전체 처리율을 높이기 위해 하나의 작업을 여러 개의 서버에서 분산하여 처리하는 방식

## 5. RTO/RPO
- RTO(Recovery Time Objective, 목표 복구 시간) : 비상사태 또는 업무 중단 시점으로부터 복구되어 가동될 때까지 소요 시간
- RPO(Recovery Point Objective, 목표 복구 시점) : 비상사태 또는 업무 중단 시점으로부터 데이터를 복구할 수 있는 기준점 